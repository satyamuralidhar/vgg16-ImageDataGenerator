{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Lambda,Dense,Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224 , 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train'\n",
    "test_path = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3] , weights = 'imagenet' , include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "folder = 'train'\n",
    "print(len(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in vgg.layers:\n",
    "    layers.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(2,activation = 'softmax')(x)\n",
    "model = Model(inputs=vgg.input , outputs = prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01,decay=1e-5,momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_set = datagen.flow_from_directory('train',batch_size=100,target_size=(224,224))\n",
    "test_set = datagen.flow_from_directory('test',batch_size=100,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dagagen = ImageDataGenerator(\n",
    "#     preprocessing_function = preprocess_input,\n",
    "#     rotation_range = 40,\n",
    "#     width_shift_range = 0.2,\n",
    "#     height_shift_range = 0.2,\n",
    "#     shear_range = 0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 406s 81s/step - loss: 5.8319 - accuracy: 0.5259 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.68955, saving model to mymodel.h5\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 282s 56s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.68955\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 221s 44s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.68955\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 213s 43s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.68955\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 210s 42s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.68955\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 209s 42s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.68955\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 206s 41s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 7.68955\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 208s 42s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.68955\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 318s 64s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.68955\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 214s 43s/step - loss: 7.4047 - accuracy: 0.5185 - val_loss: 7.6895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.68955\n",
      "training completed:  0:41:28.439328\n"
     ]
    }
   ],
   "source": [
    "#!pip install datetime\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint , LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel.h5',verbose=1,save_best_only=True)\n",
    "callbacks = [checkpoint]\n",
    "start = datetime.now()\n",
    "model.fit_generator(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=32,\n",
    "    callbacks=callbacks,verbose=1)\n",
    "duration = datetime.now() - start\n",
    "print('training completed: ',duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "img = cv2.imread('test/lepord/leopard.jpg')\n",
    "model = load_model('mymodel.h5')\n",
    "dim = (224,224)\n",
    "img = cv2.resize(img , dim , interpolation=cv2.INTER_AREA)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x , axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
